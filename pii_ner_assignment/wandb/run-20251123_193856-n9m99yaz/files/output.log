Some weights of DistilBertForTokenClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
Epoch 1/3: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625/625 [00:43<00:00, 14.32it/s]
Epoch 1 average loss: 0.2822
Epoch 2/3:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–                                                              | 258/625 [00:17<00:25, 14.56it/s][34m[1mwandb[0m: Ctrl + C detected. Stopping sweep.
Epoch 2/3:  41%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Ž                                                              | 259/625 [00:17<00:24, 14.67it/s]
Traceback (most recent call last):
  File "/home/lassen/shared/venv/lib64/python3.13/site-packages/wandb/agents/pyagent.py", line 297, in _run_job
    self._function()
    ~~~~~~~~~~~~~~^^
  File "/home/lassen/shared/GitRepos/Plivo/pii_ner_assignment/src/train.py", line 95, in train
    optimizer.step()
    ~~~~~~~~~~~~~~^^
  File "/home/lassen/shared/venv/lib64/python3.13/site-packages/torch/optim/lr_scheduler.py", line 133, in wrapper
    return func.__get__(opt, opt.__class__)(*args, **kwargs)
           ~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^
  File "/home/lassen/shared/venv/lib64/python3.13/site-packages/torch/optim/optimizer.py", line 517, in wrapper
    out = func(*args, **kwargs)
  File "/home/lassen/shared/venv/lib64/python3.13/site-packages/torch/optim/optimizer.py", line 82, in _use_grad
    ret = func(*args, **kwargs)
  File "/home/lassen/shared/venv/lib64/python3.13/site-packages/torch/optim/adam.py", line 247, in step
    adam(
    ~~~~^
        params_with_grad,
        ^^^^^^^^^^^^^^^^^
    ...<19 lines>...
        decoupled_weight_decay=group["decoupled_weight_decay"],
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/lassen/shared/venv/lib64/python3.13/site-packages/torch/optim/optimizer.py", line 150, in maybe_fallback
    return func(*args, **kwargs)
  File "/home/lassen/shared/venv/lib64/python3.13/site-packages/torch/optim/adam.py", line 953, in adam
    func(
    ~~~~^
        params,
        ^^^^^^^
    ...<17 lines>...
        decoupled_weight_decay=decoupled_weight_decay,
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
  File "/home/lassen/shared/venv/lib64/python3.13/site-packages/torch/optim/adam.py", line 781, in _multi_tensor_adam
    torch._foreach_addcdiv_(
    ~~~~~~~~~~~~~~~~~~~~~~~^
        device_params,
        ^^^^^^^^^^^^^^
    ...<2 lines>...
        step_size,  # type: ignore[arg-type]
        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    )
    ^
Exception
